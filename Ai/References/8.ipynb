{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install PyTorch Forecasting and its dependencies\n!pip install pytorch-lightning\n!pip install pytorch-forecasting\n!pip install torchmetrics\n!pip install yfinance\n!pip install plotly\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:14:57.315725Z","iopub.execute_input":"2024-12-07T08:14:57.316187Z","iopub.status.idle":"2024-12-07T08:15:50.871467Z","shell.execute_reply.started":"2024-12-07T08:14:57.316120Z","shell.execute_reply":"2024-12-07T08:15:50.869948Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torch>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.4.0+cpu)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.4)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.2)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.9.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.11.9)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\nRequirement already satisfied: pytorch-forecasting in /opt/conda/lib/python3.10/site-packages (1.2.0)\nRequirement already satisfied: numpy<=3.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (1.26.4)\nRequirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (2.4.0+cpu)\nRequirement already satisfied: lightning<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (2.4.0)\nRequirement already satisfied: scipy<2.0,>=1.8 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (1.14.1)\nRequirement already satisfied: pandas<3.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (2.2.3)\nRequirement already satisfied: scikit-learn<2.0,>=1.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (1.2.2)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.2)\nRequirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2024.9.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.11.9)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (21.3)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.6.0)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.66.4)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.12.2)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.0.3)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.7)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.6.0)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.4.0+cpu)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.9)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (70.0.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics) (2024.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.0->torchmetrics) (1.3.0)\nRequirement already satisfied: yfinance in /opt/conda/lib/python3.10/site-packages (0.2.50)\nRequirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.2.3)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.26.4)\nRequirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.32.3)\nRequirement already satisfied: multitasking>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from yfinance) (0.0.11)\nRequirement already satisfied: lxml>=4.9.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (5.3.0)\nRequirement already satisfied: platformdirs>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (3.11.0)\nRequirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2024.1)\nRequirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.4.4)\nRequirement already satisfied: peewee>=3.16.2 in /opt/conda/lib/python3.10/site-packages (from yfinance) (3.17.8)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (4.12.3)\nRequirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\nRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2024.6.2)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.22.0)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->plotly) (3.1.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport yfinance as yf\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom datetime import timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:17:56.816819Z","iopub.execute_input":"2024-12-07T08:17:56.817292Z","iopub.status.idle":"2024-12-07T08:17:59.973396Z","shell.execute_reply.started":"2024-12-07T08:17:56.817250Z","shell.execute_reply":"2024-12-07T08:17:59.972252Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Define the stock ticker\nticker = 'AAPL'  # Apple Inc.\n\n# Define the period and interval\nperiod = '5d'  # Last 5 days\ninterval = '1m'  # 1-minute intervals\n\n# Download the data\ndata = yf.download(tickers=ticker, period=period, interval=interval, progress=False)\n\n# Display the first few rows\nprint(data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:03.096239Z","iopub.execute_input":"2024-12-07T08:18:03.096900Z","iopub.status.idle":"2024-12-07T08:18:03.364422Z","shell.execute_reply.started":"2024-12-07T08:18:03.096828Z","shell.execute_reply":"2024-12-07T08:18:03.363241Z"}},"outputs":[{"name":"stdout","text":"Price                       Adj Close       Close        High         Low  \\\nTicker                           AAPL        AAPL        AAPL        AAPL   \nDatetime                                                                    \n2024-12-02 14:30:00+00:00  238.700897  238.700897  238.770004  237.160004   \n2024-12-02 14:31:00+00:00  239.000000  239.000000  239.059906  238.399994   \n2024-12-02 14:32:00+00:00  238.934601  238.934601  239.350006  238.910004   \n2024-12-02 14:33:00+00:00  239.110001  239.110001  239.199997  238.729996   \n2024-12-02 14:34:00+00:00  239.296295  239.296295  239.350006  238.929993   \n\nPrice                            Open   Volume  \nTicker                           AAPL     AAPL  \nDatetime                                        \n2024-12-02 14:30:00+00:00  237.270004  2562715  \n2024-12-02 14:31:00+00:00  238.690002   418941  \n2024-12-02 14:32:00+00:00  238.960007   213308  \n2024-12-02 14:33:00+00:00  238.929993   192847  \n2024-12-02 14:34:00+00:00  239.080093   200970  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Check if columns are MultiIndex\nif isinstance(data.columns, pd.MultiIndex):\n    # Flatten MultiIndex columns\n    data.columns = ['_'.join(col).strip() for col in data.columns.values]\n    print(\"\\nFlattened Columns:\")\n    print(data.columns)\nelse:\n    print(\"\\nColumns are already single-indexed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:08.505997Z","iopub.execute_input":"2024-12-07T08:18:08.506396Z","iopub.status.idle":"2024-12-07T08:18:08.514600Z","shell.execute_reply.started":"2024-12-07T08:18:08.506361Z","shell.execute_reply":"2024-12-07T08:18:08.513281Z"}},"outputs":[{"name":"stdout","text":"\nFlattened Columns:\nIndex(['Adj Close_AAPL', 'Close_AAPL', 'High_AAPL', 'Low_AAPL', 'Open_AAPL',\n       'Volume_AAPL'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Rename columns to remove ticker symbol\ndata.rename(columns={\n    'Open_AAPL': 'Open',\n    'High_AAPL': 'High',\n    'Low_AAPL': 'Low',\n    'Close_AAPL': 'Close',\n    'Volume_AAPL': 'Volume'\n}, inplace=True)\n\nprint(\"\\nRenamed Columns:\")\nprint(data.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:13.380695Z","iopub.execute_input":"2024-12-07T08:18:13.381115Z","iopub.status.idle":"2024-12-07T08:18:13.389263Z","shell.execute_reply.started":"2024-12-07T08:18:13.381076Z","shell.execute_reply":"2024-12-07T08:18:13.387584Z"}},"outputs":[{"name":"stdout","text":"\nRenamed Columns:\nIndex(['Adj Close_AAPL', 'Close', 'High', 'Low', 'Open', 'Volume'], dtype='object')\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(\"\\nData Types:\")\nfor col in ['High', 'Low', 'Close', 'Volume']:\n    print(f\"{col}: {type(data[col])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:17.015718Z","iopub.execute_input":"2024-12-07T08:18:17.016143Z","iopub.status.idle":"2024-12-07T08:18:17.023113Z","shell.execute_reply.started":"2024-12-07T08:18:17.016102Z","shell.execute_reply":"2024-12-07T08:18:17.021691Z"}},"outputs":[{"name":"stdout","text":"\nData Types:\nHigh: <class 'pandas.core.series.Series'>\nLow: <class 'pandas.core.series.Series'>\nClose: <class 'pandas.core.series.Series'>\nVolume: <class 'pandas.core.series.Series'>\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Step 2: Check Data Retrieval\nfrom sklearn.preprocessing import MinMaxScaler\nif data.empty:\n    print(\"DataFrame is empty. Unable to retrieve data.\")\nelse:\n    print(\"DataFrame successfully retrieved.\")\n    print(data.head())\n    print(\"Data Shape:\", data.shape)\n\n    # Step 3: Flatten MultiIndex Columns if Necessary\n    if isinstance(data.columns, pd.MultiIndex):\n        data.columns = ['_'.join(col).strip() for col in data.columns.values]\n        print(\"\\nFlattened Columns:\")\n        print(data.columns)\n    else:\n        print(\"\\nColumns are already single-indexed.\")\n\n    # Step 4: Rename Columns Appropriately\n    # Adjust this part based on your actual column names after flattening\n    rename_dict = {\n        'Open_AAPL': 'Open',\n        'High_AAPL': 'High',\n        'Low_AAPL': 'Low',\n        'Close_AAPL': 'Close',\n        'Adj Close_AAPL': 'Adj Close',\n        'Volume_AAPL': 'Volume'\n    }\n    data.rename(columns=rename_dict, inplace=True)\n    print(\"\\nRenamed Columns:\")\n    print(data.columns)\n\n    # Step 5: Handle Missing Values\n    data.dropna(inplace=True)\n    print(\"\\nData Shape after Dropping Missing Values:\", data.shape)\n\n    # Step 6: Ensure Required Columns are Numeric\n    required_columns = ['High', 'Low', 'Close', 'Volume']\n    for col in required_columns:\n        data[col] = pd.to_numeric(data[col], errors='coerce')\n    data.dropna(inplace=True)\n    print(\"\\nData Shape after Ensuring Numeric Types:\", data.shape)\n\n    # Step 7: Calculate VWAP Manually\n    # Calculate Typical Price\n    data['Typical_Price'] = (data['High'] + data['Low'] + data['Close']) / 3\n\n    # Calculate TPV (Typical Price * Volume)\n    data['TPV'] = data['Typical_Price'] * data['Volume']\n\n    # Calculate Cumulative TPV and Cumulative Volume\n    data['Cumulative_TPV'] = data['TPV'].cumsum()\n    data['Cumulative_Volume'] = data['Volume'].cumsum()\n\n    # Calculate VWAP\n    data['VWAP'] = data['Cumulative_TPV'] / data['Cumulative_Volume']\n\n    # Drop intermediate columns\n    data.drop(['Typical_Price', 'TPV', 'Cumulative_TPV', 'Cumulative_Volume'], axis=1, inplace=True)\n\n    # Handle any potential division by zero by filling NaNs\n    data['VWAP'] = data['VWAP'].bfill()  # Using backward fill as per FutureWarning\n\n    # Step 8: Calculate RSI Manually\n    rsi_period = 14\n\n    # Calculate price changes\n    data['Price_Change'] = data['Close'].diff()\n\n    # Separate gains and losses\n    data['Gain'] = data['Price_Change'].apply(lambda x: x if x > 0 else 0)\n    data['Loss'] = data['Price_Change'].apply(lambda x: -x if x < 0 else 0)\n\n    # Calculate Average Gain and Average Loss\n    data['Avg_Gain'] = data['Gain'].rolling(window=rsi_period, min_periods=rsi_period).mean()\n    data['Avg_Loss'] = data['Loss'].rolling(window=rsi_period, min_periods=rsi_period).mean()\n\n    # Calculate RS\n    data['RS'] = data['Avg_Gain'] / data['Avg_Loss']\n\n    # Calculate RSI\n    data['RSI'] = 100 - (100 / (1 + data['RS']))\n\n    # Handle NaN values in RSI\n    data['RSI'] = data['RSI'].fillna(0)\n\n    # Drop intermediate columns\n    data.drop(['Price_Change', 'Gain', 'Loss', 'Avg_Gain', 'Avg_Loss', 'RS'], axis=1, inplace=True)\n\n    # Step 9: Calculate MACD Manually\n    ema_short_period = 12\n    ema_long_period = 26\n    signal_period = 9\n\n    # Calculate EMAs\n    data['EMA_12'] = data['Close'].ewm(span=ema_short_period, adjust=False).mean()\n    data['EMA_26'] = data['Close'].ewm(span=ema_long_period, adjust=False).mean()\n\n    # Calculate MACD Line\n    data['MACD'] = data['EMA_12'] - data['EMA_26']\n\n    # Calculate Signal Line\n    data['MACD_Signal'] = data['MACD'].ewm(span=signal_period, adjust=False).mean()\n\n    # Calculate MACD Histogram\n    data['MACD_Diff'] = data['MACD'] - data['MACD_Signal']\n\n    # Drop intermediate EMA columns\n    data.drop(['EMA_12', 'EMA_26'], axis=1, inplace=True)\n\n    # Step 10: Drop any rows with NaN values from indicator calculations\n    data.dropna(inplace=True)\n    print(\"\\nData Shape after Feature Engineering:\", data.shape)\n\n    # Step 11: Normalize Data\n    scaler = MinMaxScaler()\n    scaled_features = scaler.fit_transform(data[['Close', 'Volume', 'VWAP', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Diff']])\n    data_final = pd.DataFrame(scaled_features, index=data.index, columns=['Close', 'Volume', 'VWAP', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Diff'])\n\n    print(\"\\nScaled Features Sample:\")\n    print(data_final.head())\n\n# Reset the index to make 'Datetime' a column\n\ndata_final.reset_index(inplace=True)  # 'Datetime' becomes a column\n\n# Extract time-based features\ndata_final['minute'] = data_final['Datetime'].dt.minute.astype(int)\ndata_final['hour'] = data_final['Datetime'].dt.hour.astype(int)\ndata_final['day_of_week'] = data_final['Datetime'].dt.dayofweek.astype(int)  # Monday=0, Sunday=6\ndata_final['month'] = data_final['Datetime'].dt.month.astype(int)\nprint(\"\\nDataFrame after extracting time-based features:\")\nprint(data_final.head())\nprint(\"\\nDataFrame Columns:\")\nprint(data_final.columns)\n\n# Drop the 'Datetime' column as it's no longer needed\ndata_final.drop(['Datetime'], axis=1, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:19.025578Z","iopub.execute_input":"2024-12-07T08:18:19.026026Z","iopub.status.idle":"2024-12-07T08:18:19.090421Z","shell.execute_reply.started":"2024-12-07T08:18:19.025983Z","shell.execute_reply":"2024-12-07T08:18:19.089051Z"}},"outputs":[{"name":"stdout","text":"DataFrame successfully retrieved.\n                           Adj Close_AAPL       Close        High         Low  \\\nDatetime                                                                        \n2024-12-02 14:30:00+00:00      238.700897  238.700897  238.770004  237.160004   \n2024-12-02 14:31:00+00:00      239.000000  239.000000  239.059906  238.399994   \n2024-12-02 14:32:00+00:00      238.934601  238.934601  239.350006  238.910004   \n2024-12-02 14:33:00+00:00      239.110001  239.110001  239.199997  238.729996   \n2024-12-02 14:34:00+00:00      239.296295  239.296295  239.350006  238.929993   \n\n                                 Open   Volume  \nDatetime                                        \n2024-12-02 14:30:00+00:00  237.270004  2562715  \n2024-12-02 14:31:00+00:00  238.690002   418941  \n2024-12-02 14:32:00+00:00  238.960007   213308  \n2024-12-02 14:33:00+00:00  238.929993   192847  \n2024-12-02 14:34:00+00:00  239.080093   200970  \nData Shape: (1948, 6)\n\nColumns are already single-indexed.\n\nRenamed Columns:\nIndex(['Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume'], dtype='object')\n\nData Shape after Dropping Missing Values: (1948, 6)\n\nData Shape after Ensuring Numeric Types: (1948, 6)\n\nData Shape after Feature Engineering: (1948, 11)\n\nScaled Features Sample:\n                              Close    Volume      VWAP  RSI      MACD  \\\nDatetime                                                                 \n2024-12-02 14:30:00+00:00  0.053544  1.000000  0.000000  0.0  0.441087   \n2024-12-02 14:31:00+00:00  0.101942  0.163475  0.022968  0.0  0.479813   \n2024-12-02 14:32:00+00:00  0.091360  0.083235  0.036732  0.0  0.501245   \n2024-12-02 14:33:00+00:00  0.119742  0.075251  0.046897  0.0  0.540061   \n2024-12-02 14:34:00+00:00  0.149887  0.078421  0.059012  0.0  0.593464   \n\n                           MACD_Signal  MACD_Diff  \nDatetime                                           \n2024-12-02 14:30:00+00:00     0.445894   0.501677  \n2024-12-02 14:31:00+00:00     0.454456   0.571404  \n2024-12-02 14:32:00+00:00     0.466044   0.596047  \n2024-12-02 14:33:00+00:00     0.483896   0.647061  \n2024-12-02 14:34:00+00:00     0.509985   0.714138  \n\nDataFrame after extracting time-based features:\n                   Datetime     Close    Volume      VWAP  RSI      MACD  \\\n0 2024-12-02 14:30:00+00:00  0.053544  1.000000  0.000000  0.0  0.441087   \n1 2024-12-02 14:31:00+00:00  0.101942  0.163475  0.022968  0.0  0.479813   \n2 2024-12-02 14:32:00+00:00  0.091360  0.083235  0.036732  0.0  0.501245   \n3 2024-12-02 14:33:00+00:00  0.119742  0.075251  0.046897  0.0  0.540061   \n4 2024-12-02 14:34:00+00:00  0.149887  0.078421  0.059012  0.0  0.593464   \n\n   MACD_Signal  MACD_Diff  minute  hour  day_of_week  month  \n0     0.445894   0.501677      30    14            0     12  \n1     0.454456   0.571404      31    14            0     12  \n2     0.466044   0.596047      32    14            0     12  \n3     0.483896   0.647061      33    14            0     12  \n4     0.509985   0.714138      34    14            0     12  \n\nDataFrame Columns:\nIndex(['Datetime', 'Close', 'Volume', 'VWAP', 'RSI', 'MACD', 'MACD_Signal',\n       'MACD_Diff', 'minute', 'hour', 'day_of_week', 'month'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(data_final.columns)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StockDataset(Dataset):\n    def __init__(self, data, seq_length=60, pred_length=30):\n        \"\"\"\n        Args:\n            data (pd.DataFrame): The preprocessed stock data.\n            seq_length (int): Number of past time steps to use as input.\n            pred_length (int): Number of future time steps to predict.\n        \"\"\"\n        self.data = data\n        self.seq_length = seq_length\n        self.pred_length = pred_length\n        self.total_length = seq_length + pred_length\n        self.indices = []\n        \n        for i in range(len(data) - self.total_length + 1):\n            self.indices.append(i)\n    \n    def __len__(self):\n        return len(self.indices)\n    \n    def __getitem__(self, idx):\n        start = self.indices[idx]\n        end = start + self.seq_length\n        pred_end = end + self.pred_length\n        \n        X = self.data.iloc[start:end]\n        Y = self.data.iloc[end:pred_end]['Close'].values  # Predicting 'Close' prices for future steps\n        \n        # Convert to tensors\n        X_tensor = torch.tensor(X[['Close', 'Volume', 'VWAP', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Diff']].values, dtype=torch.float32)\n        Y_tensor = torch.tensor(Y, dtype=torch.float32)  # Predicting multiple time steps, hence the length matches pred_length\n\n        # Handle categorical data similarly as before\n        minute = torch.tensor(X['minute'].astype(int).values, dtype=torch.long)\n        hour = torch.tensor(X['hour'].astype(int).values, dtype=torch.long)\n        day_of_week = torch.tensor(X['day_of_week'].astype(int).values, dtype=torch.long)\n        month = torch.tensor(X['month'].astype(int).values, dtype=torch.long)\n        \n        categorical = torch.stack([minute, hour, day_of_week, month], dim=1)  # Shape: (seq_length, num_categorical_features)\n\n        return X_tensor, categorical, Y_tensor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:33.076449Z","iopub.execute_input":"2024-12-07T08:18:33.076829Z","iopub.status.idle":"2024-12-07T08:18:33.088815Z","shell.execute_reply.started":"2024-12-07T08:18:33.076786Z","shell.execute_reply":"2024-12-07T08:18:33.087126Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Adjust 'month' to zero-based indexing\ndata_final['month'] = data_final['month'] - 1  # Convert 1-12 to 0-11\n\n# Verify the adjustment\nprint(\"\\nAfter adjusting 'month' to zero-based indexing:\")\nprint(data_final['month'].unique())\nprint(\"Min month:\", data_final['month'].min(), \"Max month:\", data_final['month'].max())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:38.655690Z","iopub.execute_input":"2024-12-07T08:18:38.656144Z","iopub.status.idle":"2024-12-07T08:18:38.664975Z","shell.execute_reply.started":"2024-12-07T08:18:38.656102Z","shell.execute_reply":"2024-12-07T08:18:38.663425Z"}},"outputs":[{"name":"stdout","text":"\nAfter adjusting 'month' to zero-based indexing:\n[11]\nMin month: 11 Max month: 11\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Verify the combined DataFrame\nprint(\"\\nCombined DataFrame with time-based features:\")\nprint(data_final.head())\n\n# Initialize the dataset\nseq_length = 60\npred_length = 30\ntrain_dataset = StockDataset(data_final, seq_length=seq_length, pred_length=pred_length)\n\n# Check a sample from the dataset\nsample_X, sample_X_cat, sample_Y = train_dataset[0]\nprint(\"\\nSample X (Numerical Features):\")\nprint(sample_X)\nprint(\"\\nSample X_cat (Categorical Features):\")\nprint(sample_X_cat)\nprint(\"\\nSample Y (Target Close Prices):\")\nprint(sample_Y)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:46.751188Z","iopub.execute_input":"2024-12-07T08:18:46.751607Z","iopub.status.idle":"2024-12-07T08:18:46.778278Z","shell.execute_reply.started":"2024-12-07T08:18:46.751568Z","shell.execute_reply":"2024-12-07T08:18:46.776968Z"}},"outputs":[{"name":"stdout","text":"\nCombined DataFrame with time-based features:\n      Close    Volume      VWAP  RSI      MACD  MACD_Signal  MACD_Diff  \\\n0  0.053544  1.000000  0.000000  0.0  0.441087     0.445894   0.501677   \n1  0.101942  0.163475  0.022968  0.0  0.479813     0.454456   0.571404   \n2  0.091360  0.083235  0.036732  0.0  0.501245     0.466044   0.596047   \n3  0.119742  0.075251  0.046897  0.0  0.540061     0.483896   0.647061   \n4  0.149887  0.078421  0.059012  0.0  0.593464     0.509985   0.714138   \n\n   minute  hour  day_of_week  month  \n0      30    14            0     11  \n1      31    14            0     11  \n2      32    14            0     11  \n3      33    14            0     11  \n4      34    14            0     11  \n\nSample X (Numerical Features):\ntensor([[0.0535, 1.0000, 0.0000, 0.0000, 0.4411, 0.4459, 0.5017],\n        [0.1019, 0.1635, 0.0230, 0.0000, 0.4798, 0.4545, 0.5714],\n        [0.0914, 0.0832, 0.0367, 0.0000, 0.5012, 0.4660, 0.5960],\n        [0.1197, 0.0753, 0.0469, 0.0000, 0.5401, 0.4839, 0.6471],\n        [0.1499, 0.0784, 0.0590, 0.0000, 0.5935, 0.5100, 0.7141],\n        [0.1481, 0.0833, 0.0717, 0.0000, 0.6321, 0.5394, 0.7412],\n        [0.1614, 0.0848, 0.0845, 0.0000, 0.6709, 0.5715, 0.7632],\n        [0.1586, 0.0524, 0.0913, 0.0000, 0.6964, 0.6028, 0.7568],\n        [0.1149, 0.0802, 0.0990, 0.0000, 0.6785, 0.6239, 0.6736],\n        [0.0844, 0.0722, 0.1030, 0.0000, 0.6374, 0.6317, 0.5652],\n        [0.0825, 0.0600, 0.1053, 0.0000, 0.6015, 0.6300, 0.4877],\n        [0.0275, 0.0469, 0.1056, 0.0000, 0.5275, 0.6123, 0.3573],\n        [0.0469, 0.0487, 0.1058, 0.0000, 0.4840, 0.5885, 0.3079],\n        [0.0000, 0.0450, 0.1049, 0.4443, 0.4119, 0.5535, 0.2169],\n        [0.0146, 0.0334, 0.1040, 0.4701, 0.3674, 0.5157, 0.1938],\n        [0.0040, 0.0472, 0.1031, 0.3621, 0.3250, 0.4761, 0.1789],\n        [0.0583, 0.0372, 0.1032, 0.4798, 0.3365, 0.4469, 0.2641],\n        [0.0113, 0.0368, 0.1030, 0.3751, 0.3091, 0.4175, 0.2623],\n        [0.0307, 0.0355, 0.1027, 0.3548, 0.3047, 0.3930, 0.3023],\n        [0.0243, 0.0356, 0.1022, 0.3502, 0.2976, 0.3719, 0.3294],\n        [0.0421, 0.0626, 0.1028, 0.3587, 0.3079, 0.3573, 0.3824],\n        [0.0307, 0.0331, 0.1025, 0.3507, 0.3085, 0.3457, 0.4073],\n        [0.0437, 0.0344, 0.1026, 0.4211, 0.3208, 0.3391, 0.4483],\n        [0.0987, 0.0637, 0.1046, 0.5498, 0.3758, 0.3460, 0.5581],\n        [0.1036, 0.0582, 0.1072, 0.5591, 0.4235, 0.3621, 0.6327],\n        [0.0874, 0.0421, 0.1087, 0.6236, 0.4482, 0.3804, 0.6509],\n        [0.1117, 0.0263, 0.1098, 0.6298, 0.4869, 0.4037, 0.6907],\n        [0.1003, 0.0304, 0.1110, 0.7032, 0.5076, 0.4268, 0.6902],\n        [0.1367, 0.0484, 0.1134, 0.7269, 0.5521, 0.4552, 0.7327],\n        [0.1513, 0.0631, 0.1172, 0.7645, 0.5975, 0.4879, 0.7681],\n        [0.1343, 0.0734, 0.1217, 0.6662, 0.6176, 0.5185, 0.7511],\n        [0.1100, 0.0532, 0.1239, 0.7217, 0.6120, 0.5418, 0.6910],\n        [0.1164, 0.0417, 0.1255, 0.7048, 0.6107, 0.5601, 0.6509],\n        [0.1440, 0.0414, 0.1275, 0.7560, 0.6298, 0.5790, 0.6555],\n        [0.1562, 0.0421, 0.1300, 0.7497, 0.6524, 0.5991, 0.6654],\n        [0.1926, 0.0646, 0.1344, 0.8157, 0.6968, 0.6250, 0.7126],\n        [0.2071, 0.0737, 0.1406, 0.8170, 0.7403, 0.6553, 0.7488],\n        [0.2265, 0.0462, 0.1446, 0.7845, 0.7866, 0.6898, 0.7826],\n        [0.1845, 0.0369, 0.1473, 0.6710, 0.7852, 0.7171, 0.7239],\n        [0.1683, 0.0459, 0.1498, 0.6710, 0.7672, 0.7350, 0.6471],\n        [0.1717, 0.0242, 0.1512, 0.6423, 0.7522, 0.7459, 0.5910],\n        [0.2063, 0.0418, 0.1539, 0.7135, 0.7645, 0.7574, 0.5954],\n        [0.2201, 0.0356, 0.1566, 0.6857, 0.7815, 0.7704, 0.6072],\n        [0.2168, 0.0468, 0.1602, 0.6575, 0.7884, 0.7823, 0.5985],\n        [0.2201, 0.0334, 0.1627, 0.7060, 0.7924, 0.7927, 0.5863],\n        [0.2410, 0.0368, 0.1655, 0.8026, 0.8083, 0.8045, 0.5980],\n        [0.2193, 0.0329, 0.1679, 0.7318, 0.7992, 0.8120, 0.5624],\n        [0.2414, 0.0214, 0.1695, 0.7250, 0.8057, 0.8194, 0.5619],\n        [0.2359, 0.0352, 0.1722, 0.6936, 0.8022, 0.8245, 0.5435],\n        [0.2092, 0.0391, 0.1747, 0.5651, 0.7739, 0.8224, 0.4843],\n        [0.2273, 0.0231, 0.1762, 0.5721, 0.7626, 0.8181, 0.4673],\n        [0.2298, 0.0305, 0.1783, 0.5368, 0.7519, 0.8124, 0.4550],\n        [0.2087, 0.0364, 0.1805, 0.5898, 0.7232, 0.8015, 0.4127],\n        [0.2120, 0.0253, 0.1820, 0.6450, 0.7001, 0.7876, 0.3889],\n        [0.2225, 0.0161, 0.1830, 0.6592, 0.6875, 0.7738, 0.3886],\n        [0.2557, 0.0542, 0.1869, 0.6564, 0.7013, 0.7657, 0.4361],\n        [0.2605, 0.0556, 0.1910, 0.6382, 0.7130, 0.7619, 0.4704],\n        [0.2557, 0.0621, 0.1955, 0.6330, 0.7153, 0.7593, 0.4807],\n        [0.2581, 0.0726, 0.2007, 0.6313, 0.7158, 0.7574, 0.4859],\n        [0.3074, 0.4437, 0.2334, 0.6850, 0.7526, 0.7639, 0.5553]])\n\nSample X_cat (Categorical Features):\ntensor([[30, 14,  0, 11],\n        [31, 14,  0, 11],\n        [32, 14,  0, 11],\n        [33, 14,  0, 11],\n        [34, 14,  0, 11],\n        [35, 14,  0, 11],\n        [36, 14,  0, 11],\n        [37, 14,  0, 11],\n        [38, 14,  0, 11],\n        [39, 14,  0, 11],\n        [40, 14,  0, 11],\n        [41, 14,  0, 11],\n        [42, 14,  0, 11],\n        [43, 14,  0, 11],\n        [44, 14,  0, 11],\n        [45, 14,  0, 11],\n        [46, 14,  0, 11],\n        [47, 14,  0, 11],\n        [48, 14,  0, 11],\n        [49, 14,  0, 11],\n        [50, 14,  0, 11],\n        [51, 14,  0, 11],\n        [52, 14,  0, 11],\n        [53, 14,  0, 11],\n        [54, 14,  0, 11],\n        [55, 14,  0, 11],\n        [56, 14,  0, 11],\n        [57, 14,  0, 11],\n        [58, 14,  0, 11],\n        [59, 14,  0, 11],\n        [ 0, 15,  0, 11],\n        [ 1, 15,  0, 11],\n        [ 2, 15,  0, 11],\n        [ 3, 15,  0, 11],\n        [ 4, 15,  0, 11],\n        [ 5, 15,  0, 11],\n        [ 6, 15,  0, 11],\n        [ 7, 15,  0, 11],\n        [ 8, 15,  0, 11],\n        [ 9, 15,  0, 11],\n        [10, 15,  0, 11],\n        [11, 15,  0, 11],\n        [12, 15,  0, 11],\n        [13, 15,  0, 11],\n        [14, 15,  0, 11],\n        [15, 15,  0, 11],\n        [16, 15,  0, 11],\n        [17, 15,  0, 11],\n        [18, 15,  0, 11],\n        [19, 15,  0, 11],\n        [20, 15,  0, 11],\n        [21, 15,  0, 11],\n        [22, 15,  0, 11],\n        [23, 15,  0, 11],\n        [24, 15,  0, 11],\n        [25, 15,  0, 11],\n        [26, 15,  0, 11],\n        [27, 15,  0, 11],\n        [28, 15,  0, 11],\n        [29, 15,  0, 11]])\n\nSample Y (Target Close Prices):\ntensor([0.3398, 0.3744, 0.3471, 0.3528, 0.3754, 0.3576, 0.3350, 0.3528, 0.3843,\n        0.3819, 0.3746, 0.3196, 0.3220, 0.3034, 0.2961, 0.3123, 0.3272, 0.3317,\n        0.2954, 0.2945, 0.3139, 0.3238, 0.3139, 0.2848, 0.2799, 0.2557, 0.2589,\n        0.2783, 0.2589, 0.2654])\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Split the data into training and validation sets (80-20 split)\ntrain_size = int(len(data_final) * 0.8)\ntrain_df = data_final.iloc[:train_size].copy()\nval_df = data_final.iloc[train_size - seq_length - pred_length + 1 :].copy()  # Ensure enough data for sequences\n\nprint(f\"\\nTraining data points: {len(train_df)}\")\nprint(f\"Validation data points: {len(val_df)}\")\n\n# Create training and validation datasets\ntrain_dataset = StockDataset(train_df, seq_length=seq_length, pred_length=pred_length)\nval_dataset = StockDataset(val_df, seq_length=seq_length, pred_length=pred_length)\n\nprint(f\"\\nNumber of training samples: {len(train_dataset)}\")\nprint(f\"Number of validation samples: {len(val_dataset)}\")\n\n# Define batch size\nbatch_size = 64\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n\nprint(f\"\\nNumber of batches in training loader: {len(train_loader)}\")\nprint(f\"Number of batches in validation loader: {len(val_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:53.506340Z","iopub.execute_input":"2024-12-07T08:18:53.507712Z","iopub.status.idle":"2024-12-07T08:18:53.520439Z","shell.execute_reply.started":"2024-12-07T08:18:53.507648Z","shell.execute_reply":"2024-12-07T08:18:53.518838Z"}},"outputs":[{"name":"stdout","text":"\nTraining data points: 1558\nValidation data points: 479\n\nNumber of training samples: 1469\nNumber of validation samples: 390\n\nNumber of batches in training loader: 22\nNumber of batches in validation loader: 6\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"class VariableSelectionNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size=512, output_size=39, dropout=0.1):\n        \"\"\"\n        Variable Selection Network to assign weights to each feature.\n        \n        Args:\n            input_size (int): Number of input features (39).\n            hidden_size (int): Number of hidden units.\n            output_size (int): Number of output features (should match input_size).\n            dropout (float): Dropout rate.\n        \"\"\"\n        super(VariableSelectionNetwork, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_size, output_size)  # Set output size to match input features (39)\n        self.softmax = nn.Softmax(dim=2)  # Apply softmax over the feature dimension (dim=2)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass for Variable Selection Network.\n        \n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, seq_length, input_size).\n        \n        Returns:\n            selected (torch.Tensor): Weighted sum of features of shape (batch_size, seq_length).\n            weights (torch.Tensor): Weights for each feature of shape (batch_size, seq_length, output_size).\n        \"\"\"\n        weights = self.fc1(x)  # (batch_size, seq_length, hidden_size)\n        weights = self.relu(weights)\n        weights = self.dropout(weights)\n        weights = self.fc2(weights)  # (batch_size, seq_length, output_size=39)\n        weights = self.softmax(weights)  # (batch_size, seq_length, 39)\n        \n        # Weighted sum: Multiply and sum along the feature dimension\n        selected = torch.sum(weights * x, dim=2)  # (batch_size, seq_length)\n        \n        return selected, weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:00.912540Z","iopub.execute_input":"2024-12-07T08:19:00.912955Z","iopub.status.idle":"2024-12-07T08:19:00.921729Z","shell.execute_reply.started":"2024-12-07T08:19:00.912908Z","shell.execute_reply":"2024-12-07T08:19:00.920635Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class GatedResidualNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n        super(GatedResidualNetwork, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_size, output_size)\n        self.gate = nn.Linear(input_size, output_size)\n        self.layer_norm = nn.LayerNorm(output_size)\n    \n    def forward(self, x):\n        \"\"\"\n        x: (batch_size, seq_length, input_size)\n        Returns:\n            out: (batch_size, seq_length, output_size)\n        \"\"\"\n        # Main pathway\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        \n        # Gating mechanism\n        gate = torch.sigmoid(self.gate(x))\n        \n        # Apply gate\n        out = out * gate\n        \n        # Residual connection and layer normalization\n        out = self.layer_norm(out + x)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:04.286504Z","iopub.execute_input":"2024-12-07T08:19:04.286933Z","iopub.status.idle":"2024-12-07T08:19:04.295183Z","shell.execute_reply.started":"2024-12-07T08:19:04.286883Z","shell.execute_reply":"2024-12-07T08:19:04.293989Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class MultiHeadAttentionLayer(nn.Module):\n    def __init__(self, embed_size, heads, dropout=0.1):\n        super(MultiHeadAttentionLayer, self).__init__()\n        self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads, dropout=dropout, batch_first=True)\n        self.layer_norm = nn.LayerNorm(embed_size)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        \"\"\"\n        x: (batch_size, seq_length, embed_size)\n        Returns:\n            out: (batch_size, seq_length, embed_size)\n        \"\"\"\n        attn_output, _ = self.attention(x, x, x)\n        out = self.layer_norm(attn_output + x)\n        out = self.dropout(out)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:07.106665Z","iopub.execute_input":"2024-12-07T08:19:07.107770Z","iopub.status.idle":"2024-12-07T08:19:07.114646Z","shell.execute_reply.started":"2024-12-07T08:19:07.107709Z","shell.execute_reply":"2024-12-07T08:19:07.113400Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class TemporalFusionLayer(nn.Module):\n    def __init__(self, embed_size, lstm_hidden_size, lstm_layers=4, attention_heads=4, dropout=0.1):\n        super(TemporalFusionLayer, self).__init__()\n        self.lstm = nn.LSTM(input_size=embed_size, hidden_size=lstm_hidden_size, num_layers=lstm_layers, batch_first=True, dropout=dropout)\n        self.attention = MultiHeadAttentionLayer(embed_size=lstm_hidden_size, heads=attention_heads, dropout=dropout)\n        self.layer_norm = nn.LayerNorm(lstm_hidden_size)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        \"\"\"\n        x: (batch_size, seq_length, embed_size)\n        Returns:\n            out: (batch_size, seq_length, lstm_hidden_size)\n        \"\"\"\n        lstm_out, _ = self.lstm(x)  # (batch_size, seq_length, lstm_hidden_size)\n        attn_out = self.attention(lstm_out)  # (batch_size, seq_length, lstm_hidden_size)\n        out = self.layer_norm(attn_out + lstm_out)\n        out = self.dropout(out)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:10.831020Z","iopub.execute_input":"2024-12-07T08:19:10.831437Z","iopub.status.idle":"2024-12-07T08:19:10.839537Z","shell.execute_reply.started":"2024-12-07T08:19:10.831399Z","shell.execute_reply":"2024-12-07T08:19:10.838281Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class StaticEnrichment(nn.Module):\n    def __init__(self, static_size, embed_size, dropout=0.1):\n        super(StaticEnrichment, self).__init__()\n        self.fc = nn.Linear(static_size, embed_size)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        \"\"\"\n        x: (batch_size, static_size)\n        Returns:\n            enriched: (batch_size, embed_size)\n        \"\"\"\n        enriched = self.fc(x)\n        enriched = self.relu(enriched)\n        enriched = self.dropout(enriched)\n        return enriched\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:14.136163Z","iopub.execute_input":"2024-12-07T08:19:14.136565Z","iopub.status.idle":"2024-12-07T08:19:14.144457Z","shell.execute_reply.started":"2024-12-07T08:19:14.136520Z","shell.execute_reply":"2024-12-07T08:19:14.143390Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class OutputLayer(nn.Module):\n    def __init__(self, lstm_hidden_size, pred_length):\n        super(OutputLayer, self).__init__()\n        self.fc = nn.Linear(lstm_hidden_size, pred_length)\n    \n    def forward(self, x):\n        \"\"\"\n        x: (batch_size, lstm_hidden_size)\n        Returns:\n            out: (batch_size, pred_length)\n        \"\"\"\n        out = self.fc(x)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:16.506232Z","iopub.execute_input":"2024-12-07T08:19:16.506722Z","iopub.status.idle":"2024-12-07T08:19:16.513174Z","shell.execute_reply.started":"2024-12-07T08:19:16.506667Z","shell.execute_reply":"2024-12-07T08:19:16.511841Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass TemporalFusionTransformer(nn.Module):\n    def __init__(self, \n                 input_size, \n                 categorical_size, \n                 static_size, \n                 embed_size=64, \n                 lstm_hidden_size=512, \n                 lstm_layers=4, \n                 attention_heads=4, \n                 dropout=0.1, \n                 pred_length=30):\n        super(TemporalFusionTransformer, self).__init__()\n        self.input_size = input_size\n        self.categorical_size = categorical_size\n        self.static_size = static_size\n        self.embed_size = embed_size\n        self.lstm_hidden_size = lstm_hidden_size\n        self.lstm_layers = lstm_layers\n        self.attention_heads = attention_heads\n        self.dropout = dropout\n        self.pred_length = pred_length\n        \n        # Embedding layers for categorical features\n        self.embedding_minute = nn.Embedding(num_embeddings=60, embedding_dim=8)\n        self.embedding_hour = nn.Embedding(num_embeddings=24, embedding_dim=8)\n        self.embedding_day_of_week = nn.Embedding(num_embeddings=7, embedding_dim=8)\n        self.embedding_month = nn.Embedding(num_embeddings=12, embedding_dim=8)  # 0-11\n        \n        # Variable Selection Network\n        self.variable_selection = VariableSelectionNetwork(input_size=self.input_size + 4 * 8)  # 7 + 32 = 39\n        \n        # Projection Layer after Variable Selection\n        self.projection = nn.Linear(1, self.embed_size)  # Map from scalar to embed_size\n        \n        # Gated Residual Network\n        self.grn = GatedResidualNetwork(input_size=self.embed_size, hidden_size=64, output_size=self.embed_size, dropout=self.dropout)\n        \n        # Temporal Fusion Layer\n        self.temporal_fusion = TemporalFusionLayer(embed_size=self.embed_size, \n                                                  lstm_hidden_size=self.lstm_hidden_size, \n                                                  lstm_layers=self.lstm_layers, \n                                                  attention_heads=self.attention_heads, \n                                                  dropout=self.dropout)\n        \n        # Output Layer: Mapping to a single predicted value per time step\n        self.output_layer = nn.Linear(self.lstm_hidden_size, 1)  # Produces a single value per time step\n    \n    def forward(self, X_real, X_cat, X_static):\n        \"\"\"\n        Args:\n            X_real: (batch_size, seq_length, input_size) - Real-valued features\n            X_cat: (batch_size, seq_length, categorical_size) - Categorical features\n            X_static: (batch_size, static_size) - Static features\n        Returns:\n            out: (batch_size, pred_length)\n        \"\"\"\n        batch_size, seq_length, _ = X_real.size()\n        \n        # Embed categorical features\n        minute = self.embedding_minute(X_cat[:, :, 0])  # (batch_size, seq_length, 8)\n        hour = self.embedding_hour(X_cat[:, :, 1])      # (batch_size, seq_length, 8)\n        day_of_week = self.embedding_day_of_week(X_cat[:, :, 2])  # (batch_size, seq_length, 8)\n        month = self.embedding_month(X_cat[:, :, 3])    # (batch_size, seq_length, 8)\n        \n        # Concatenate embedded categorical features with real features\n        X = torch.cat([X_real, minute, hour, day_of_week, month], dim=2)  # (batch_size, seq_length, 39)\n        \n        # Variable Selection\n        X_selected, weights = self.variable_selection(X)  # X_selected: (batch_size, seq_length)\n        \n        # Reshape X_selected for projection\n        X_selected = X_selected.unsqueeze(-1)  # (batch_size, seq_length, 1)\n        \n        # Project to embed_size\n        X_selected = self.projection(X_selected)  # (batch_size, seq_length, embed_size)\n        \n        # Gated Residual Network\n        X_grn = self.grn(X_selected)  # (batch_size, seq_length, embed_size)\n        \n        # Temporal Fusion Layer\n        X_temporal = self.temporal_fusion(X_grn)  # (batch_size, seq_length, lstm_hidden_size)\n        \n        # Take the last 'pred_length' time steps\n        X_temporal_last = X_temporal[:, -self.pred_length:, :]  # (batch_size, pred_length, lstm_hidden_size)\n        \n        # Output Layer\n        out = self.output_layer(X_temporal_last)  # (batch_size, pred_length, 1)\n        \n        # Squeeze the output to get rid of the singleton dimension\n        out = out.squeeze(-1)  # (batch_size, pred_length)\n        \n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:19.516817Z","iopub.execute_input":"2024-12-07T08:19:19.517274Z","iopub.status.idle":"2024-12-07T08:19:19.531635Z","shell.execute_reply.started":"2024-12-07T08:19:19.517234Z","shell.execute_reply":"2024-12-07T08:19:19.530368Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Initialize the model\ninput_size = 7  # ['Open', 'High', 'Low', 'Close', 'Volume', 'MA_5', 'MA_10', 'MA_20', 'Return']\ncategorical_size = 4 # ['minute', 'hour', 'day_of_week', 'day_of_month', 'month', 'year']\nstatic_size = 0  # No static features in this setup\n\n# Instantiate the model\nmodel = TemporalFusionTransformer(\n    input_size=input_size,\n    categorical_size=categorical_size,\n    static_size=static_size,\n    embed_size=64,\n    lstm_hidden_size=512,\n    lstm_layers=4,\n    attention_heads=4,\n    dropout=0.1,\n    pred_length=pred_length\n)\n\n# Define the device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Define the loss function\ncriterion = nn.MSELoss()\n\n# Define the optimizer\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:23.610612Z","iopub.execute_input":"2024-12-07T08:19:23.611089Z","iopub.status.idle":"2024-12-07T08:19:24.408122Z","shell.execute_reply.started":"2024-12-07T08:19:23.611045Z","shell.execute_reply":"2024-12-07T08:19:24.406970Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"print(f\"\\nVariableSelectionNetwork input size: {model.variable_selection.fc1.in_features}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:26.210345Z","iopub.execute_input":"2024-12-07T08:19:26.210993Z","iopub.status.idle":"2024-12-07T08:19:26.217723Z","shell.execute_reply.started":"2024-12-07T08:19:26.210951Z","shell.execute_reply":"2024-12-07T08:19:26.216606Z"}},"outputs":[{"name":"stdout","text":"\nVariableSelectionNetwork input size: 39\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, device, epochs):\n    for epoch in range(epochs):\n        model.train()\n        for batch_idx, (X_real, X_cat, Y) in enumerate(train_loader):\n            X_real = X_real.to(device)\n            X_cat = X_cat.to(device)\n            Y = Y.to(device)\n\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(X_real, X_cat, torch.zeros((X_real.size(0), static_size)).to(device))  # (batch_size, pred_length)\n            \n            # Ensure `Y` and `outputs` have the same shape\n            assert outputs.shape == Y.shape, f\"Shape mismatch: outputs shape {outputs.shape} and Y shape {Y.shape}\"\n\n            # Calculate loss\n            loss = criterion(outputs, Y)  # Shapes must match here\n            loss.backward()\n            optimizer.step()\n            \n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:29.211223Z","iopub.execute_input":"2024-12-07T08:19:29.211666Z","iopub.status.idle":"2024-12-07T08:19:29.219809Z","shell.execute_reply.started":"2024-12-07T08:19:29.211625Z","shell.execute_reply":"2024-12-07T08:19:29.218607Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def evaluate(model, val_loader, criterion, device):\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for X_real, X_cat, Y in val_loader:\n            X_real = X_real.to(device)\n            X_cat = X_cat.to(device)\n            Y = Y.to(device)\n            \n            outputs = model(X_real, X_cat, torch.zeros((X_real.size(0), static_size)).to(device))  # No static features\n            loss = criterion(outputs, Y)\n            val_loss += loss.item()\n    model.train()\n    return val_loss / len(val_loader)\n\n# Save the model state dict\ntorch.save(model.state_dict(), \"model.pth\")\n\n# Or save the entire model\ntorch.save(model, \"model_full.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:32.856011Z","iopub.execute_input":"2024-12-07T08:19:32.856528Z","iopub.status.idle":"2024-12-07T08:19:33.020840Z","shell.execute_reply.started":"2024-12-07T08:19:32.856472Z","shell.execute_reply":"2024-12-07T08:19:33.019418Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Check the unique values and range of 'month'\nprint(\"\\nUnique 'month' values in the dataset:\")\nprint(data_final['month'].unique())\n\nprint(\"\\nMinimum and Maximum 'month' values:\")\nprint(data_final['month'].min(), data_final['month'].max())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:36.261912Z","iopub.execute_input":"2024-12-07T08:19:36.262318Z","iopub.status.idle":"2024-12-07T08:19:36.271223Z","shell.execute_reply.started":"2024-12-07T08:19:36.262281Z","shell.execute_reply":"2024-12-07T08:19:36.268203Z"}},"outputs":[{"name":"stdout","text":"\nUnique 'month' values in the dataset:\n[11]\n\nMinimum and Maximum 'month' values:\n11 11\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# List of categorical features\ncategorical_features = ['minute', 'hour', 'day_of_week', 'month']\n\n# Verify all categorical features are present\nprint(\"\\nCategorical Features Present in data_final:\")\nprint(data_final[categorical_features].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:39.095808Z","iopub.execute_input":"2024-12-07T08:19:39.096247Z","iopub.status.idle":"2024-12-07T08:19:39.106082Z","shell.execute_reply.started":"2024-12-07T08:19:39.096207Z","shell.execute_reply":"2024-12-07T08:19:39.104553Z"}},"outputs":[{"name":"stdout","text":"\nCategorical Features Present in data_final:\n   minute  hour  day_of_week  month\n0      30    14            0     11\n1      31    14            0     11\n2      32    14            0     11\n3      33    14            0     11\n4      34    14            0     11\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Fetch a single batch\nX_real, X_cat, Y = next(iter(train_loader))\n\n# Move to device\nX_real = X_real.to(device)\nX_cat = X_cat.to(device)\nY = Y.to(device)\n\n# Forward pass\noutputs = model(X_real, X_cat, torch.zeros((X_real.size(0), static_size)).to(device))\nprint(f\"\\nOutput shape: {outputs.shape}\")  # Should be (batch_size, pred_length)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:42.740953Z","iopub.execute_input":"2024-12-07T08:19:42.741335Z","iopub.status.idle":"2024-12-07T08:19:43.722206Z","shell.execute_reply.started":"2024-12-07T08:19:42.741302Z","shell.execute_reply":"2024-12-07T08:19:43.721229Z"}},"outputs":[{"name":"stdout","text":"\nOutput shape: torch.Size([64, 30])\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"print(f\"\\nVariableSelectionNetwork output size: {model.variable_selection.fc2.out_features}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"\\nProjection Layer: {model.projection}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:49.422239Z","iopub.execute_input":"2024-12-07T08:19:49.422649Z","iopub.status.idle":"2024-12-07T08:19:49.428341Z","shell.execute_reply.started":"2024-12-07T08:19:49.422611Z","shell.execute_reply":"2024-12-07T08:19:49.427225Z"}},"outputs":[{"name":"stdout","text":"\nProjection Layer: Linear(in_features=1, out_features=64, bias=True)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Train the model\nepochs = 20\ntrain(model, train_loader, val_loader, criterion, optimizer, device, epochs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:20:35.096256Z","iopub.execute_input":"2024-12-07T08:20:35.096685Z","iopub.status.idle":"2024-12-07T08:36:34.347033Z","shell.execute_reply.started":"2024-12-07T08:20:35.096644Z","shell.execute_reply":"2024-12-07T08:36:34.345783Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/20], Loss: 0.0760\nEpoch [2/20], Loss: 0.0612\nEpoch [3/20], Loss: 0.0687\nEpoch [4/20], Loss: 0.0580\nEpoch [5/20], Loss: 0.0680\nEpoch [6/20], Loss: 0.0644\nEpoch [7/20], Loss: 0.0585\nEpoch [8/20], Loss: 0.0201\nEpoch [9/20], Loss: 0.0164\nEpoch [10/20], Loss: 0.0135\nEpoch [11/20], Loss: 0.0107\nEpoch [12/20], Loss: 0.0100\nEpoch [13/20], Loss: 0.0096\nEpoch [14/20], Loss: 0.0089\nEpoch [15/20], Loss: 0.0087\nEpoch [16/20], Loss: 0.0072\nEpoch [17/20], Loss: 0.0062\nEpoch [18/20], Loss: 0.0053\nEpoch [19/20], Loss: 0.0048\nEpoch [20/20], Loss: 0.0045\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def predict(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actuals = []\n    with torch.no_grad():\n        for X_real, X_cat, Y in data_loader:\n            X_real = X_real.to(device)\n            X_cat = X_cat.to(device)\n            Y = Y.to(device)\n            \n            outputs = model(X_real, X_cat, torch.zeros((X_real.size(0), static_size)).to(device))  # No static features\n            predictions.append(outputs.cpu().numpy())\n            actuals.append(Y.cpu().numpy())\n    return np.concatenate(predictions), np.concatenate(actuals)\n\n# Get predictions and actuals\npreds, trues = predict(model, val_loader, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:36:48.963505Z","iopub.execute_input":"2024-12-07T08:36:48.963945Z","iopub.status.idle":"2024-12-07T08:36:53.375007Z","shell.execute_reply.started":"2024-12-07T08:36:48.963906Z","shell.execute_reply":"2024-12-07T08:36:53.373921Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"pip install torchviz\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nsave_path = '/kaggle/working/trained_model.pth'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Flatten the arrays\npreds_flat = preds.flatten()\ntrues_flat = trues.flatten()\n\n# Calculate MAE and RMSE\nmae = mean_absolute_error(trues_flat, preds_flat)\nrmse = np.sqrt(mean_squared_error(trues_flat, preds_flat))\n\nprint(f\"Validation MAE: {mae:.4f}\")\nprint(f\"Validation RMSE: {rmse:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot for the first sample in the validation set\nsample_idx = 0\n\nplt.figure(figsize=(12,6))\nplt.plot(trues[sample_idx], label='Actual Close Price')\nplt.plot(preds[sample_idx], label='Predicted Close Price')\nplt.title(f\"Close Price Forecast - Sample {sample_idx+1}\")\nplt.xlabel(\"Prediction Time Steps\")\nplt.ylabel(\"Close Price (Standardized)\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inverse transform using the scaler\ntrues_original = scaler.inverse_transform(train_data[['Open', 'High', 'Low', 'Close', 'Volume', \n                                                    'MA_5', 'MA_10', 'MA_20', 'Return']].values)[:,3]  # 'Close' is the 4th column\npreds_original = scaler.inverse_transform(train_data[['Open', 'High', 'Low', 'Close', 'Volume', \n                                                    'MA_5', 'MA_10', 'MA_20', 'Return']].values)[:,3]\n\n# Adjust accordingly if using different splits\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select a sample from validation set\nsample_idx = 0\n\n# Inverse transform\nY_true = trues[sample_idx]\nY_pred = preds[sample_idx]\n\n# Since scaling was applied, we need to inverse it\n# Extract only the 'Close' feature\n# Assuming 'Close' is the 4th column in features_to_scale\nclose_index = features_to_scale.index('Close')\nY_true_original = scaler.inverse_transform(np.concatenate([np.zeros((len(Y_true), close_index)), Y_true.reshape(-1,1), \n                                                             np.zeros((len(Y_true), len(features_to_scale)-close_index-1))], axis=1))[:, close_index]\nY_pred_original = scaler.inverse_transform(np.concatenate([np.zeros((len(Y_pred), close_index)), Y_pred.reshape(-1,1), \n                                                             np.zeros((len(Y_pred), len(features_to_scale)-close_index-1))], axis=1))[:, close_index]\n\nplt.figure(figsize=(12,6))\nplt.plot(Y_true_original, label='Actual Close Price')\nplt.plot(Y_pred_original, label='Predicted Close Price')\nplt.title(f\"Close Price Forecast - Sample {sample_idx+1}\")\nplt.xlabel(\"Prediction Time Steps\")\nplt.ylabel(\"Close Price ($)\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_future_data(model, last_seq, future_steps, scaler, device):\n    \"\"\"\n    Args:\n        model: Trained TFT model\n        last_seq (pd.DataFrame): The last 'seq_length' minutes of data\n        future_steps (int): Number of future minutes to predict\n        scaler: Fitted scaler\n        device: torch device\n    Returns:\n        future_preds: Predicted 'Close' prices for future_steps\n    \"\"\"\n    model.eval()\n    with torch.no_grad():\n        # Prepare the input tensors\n        X_real = torch.tensor(last_seq[['Open', 'High', 'Low', 'Close', 'Volume', \n                                        'MA_5', 'MA_10', 'MA_20', 'Return']].values, dtype=torch.float32).unsqueeze(0).to(device)  # (1, seq_length, input_size)\n        \n        X_cat = torch.tensor(last_seq[['minute', 'hour', 'day_of_week', 'day_of_month', 'month', 'year']].astype(int).values, dtype=torch.long).unsqueeze(0).to(device)  # (1, seq_length, categorical_size)\n        \n        X_static = torch.zeros((1, static_size)).to(device)  # No static features\n        \n        # Predict\n        preds = model(X_real, X_cat, X_static)  # (1, pred_length)\n        \n        # Convert to CPU and numpy\n        preds = preds.cpu().numpy().flatten()\n        \n        # Inverse transform\n        # Since only 'Close' was scaled, set other features to zero\n        preds_scaled = np.concatenate([np.zeros((future_steps, close_index)), preds.reshape(-1,1), \n                                       np.zeros((future_steps, len(features_to_scale)-close_index-1))], axis=1)\n        preds_original = scaler.inverse_transform(preds_scaled)[:, close_index]\n        \n        return preds_original\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Number of future steps to predict\nfuture_steps = 30  # Next 30 minutes\n\n# Get the last 'seq_length' minutes from the validation set\nlast_seq = val_data.iloc[-seq_length:]\n\n# Prepare and predict\nfuture_preds = prepare_future_data(model, last_seq, future_steps, scaler, device)\n\n# Display the future predictions\nprint(f\"Future {future_steps} minutes predictions for {ticker}:\")\nprint(future_preds)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot future predictions\nplt.figure(figsize=(12,6))\nplt.plot(range(future_steps), future_preds, label='Predicted Close Price')\nplt.title(f\"Future {future_steps} Minutes Close Price Forecast for {ticker}\")\nplt.xlabel(\"Future Time Steps\")\nplt.ylabel(\"Close Price ($)\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}